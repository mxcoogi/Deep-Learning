{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9952563-0fc3-45b1-812c-2307a6627fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ad6476-6689-4f7d-8daf-394947150d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'img.jpg'\n",
    "img = image.load_img(img_path, target_size = (224,224))\n",
    "#target_size : 원하는 이미지 크기로 변\n",
    "Image\n",
    "x = image.img_to_array(img)\n",
    "#이미지를 행렬로 바꿔주는 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709708c6-0722-4b5a-8120-66023dc1f6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[241., 252., 113.],\n",
       "        [240., 252., 118.],\n",
       "        [237., 252., 125.],\n",
       "        ...,\n",
       "        [246., 253., 255.],\n",
       "        [227., 245., 255.],\n",
       "        [195., 224., 228.]],\n",
       "\n",
       "       [[240., 252., 114.],\n",
       "        [239., 252., 120.],\n",
       "        [236., 251., 126.],\n",
       "        ...,\n",
       "        [223., 245., 255.],\n",
       "        [200., 229., 233.],\n",
       "        [158., 192., 167.]],\n",
       "\n",
       "       [[240., 252., 118.],\n",
       "        [239., 251., 123.],\n",
       "        [236., 252., 128.],\n",
       "        ...,\n",
       "        [190., 224., 236.],\n",
       "        [153., 187., 163.],\n",
       "        [124., 156.,  83.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [255., 255., 255.],\n",
       "        [255., 253., 254.],\n",
       "        ...,\n",
       "        [ 67.,  76.,  71.],\n",
       "        [ 64.,  75.,  71.],\n",
       "        [ 58.,  68.,  67.]],\n",
       "\n",
       "       [[255., 255., 255.],\n",
       "        [254., 254., 254.],\n",
       "        [255., 255., 255.],\n",
       "        ...,\n",
       "        [ 69.,  80.,  74.],\n",
       "        [ 66.,  79.,  72.],\n",
       "        [ 60.,  72.,  68.]],\n",
       "\n",
       "       [[250., 252., 251.],\n",
       "        [253., 255., 254.],\n",
       "        [254., 255., 255.],\n",
       "        ...,\n",
       "        [ 75.,  88.,  79.],\n",
       "        [ 71.,  87.,  77.],\n",
       "        [ 66.,  81.,  74.]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6815b09e-6a1d-49e6-b066-9558043f021a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d623a7-4338-4737-8f4e-1d3fcee6437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#대부분의 이미지 분류 모델은 여러 개의 데이터를 한번에 입력받음\n",
    "# 하나의 이미지는 한번 묶어줘야함\n",
    "# 차원을 확장한다고 표현\n",
    "x = np.expand_dims(x, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db50923a-3d7b-492a-beee-eb842b8fa8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46495156-5694-4b53-aed3-d5ca5bd30a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 정규화\n",
    "#0 ~ 255인 픽셀 값을 모델에 맞는 특정 범위로 변환하는 작업\n",
    "#0 ~ 1 or -1 ~ 1\n",
    "#모델의 정규화 방법을 알아내는 방법은 모델을 제안한 논문 참고 or 코드 참"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230db619-a665-43a1-bf40-a2bc523bb92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenet 의 전처리 함수\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b39615ee-edb8-41df-b447-979ef5df2fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.8901961 ,  0.9764706 , -0.11372548],\n",
       "         [ 0.88235295,  0.9764706 , -0.0745098 ],\n",
       "         [ 0.85882354,  0.9764706 , -0.01960784],\n",
       "         ...,\n",
       "         [ 0.92941177,  0.9843137 ,  1.        ],\n",
       "         [ 0.78039217,  0.92156863,  1.        ],\n",
       "         [ 0.5294118 ,  0.75686276,  0.7882353 ]],\n",
       "\n",
       "        [[ 0.88235295,  0.9764706 , -0.10588235],\n",
       "         [ 0.8745098 ,  0.9764706 , -0.05882353],\n",
       "         [ 0.8509804 ,  0.96862745, -0.01176471],\n",
       "         ...,\n",
       "         [ 0.7490196 ,  0.92156863,  1.        ],\n",
       "         [ 0.5686275 ,  0.79607844,  0.827451  ],\n",
       "         [ 0.23921573,  0.5058824 ,  0.30980396]],\n",
       "\n",
       "        [[ 0.88235295,  0.9764706 , -0.0745098 ],\n",
       "         [ 0.8745098 ,  0.96862745, -0.03529412],\n",
       "         [ 0.8509804 ,  0.9764706 ,  0.00392163],\n",
       "         ...,\n",
       "         [ 0.4901961 ,  0.75686276,  0.8509804 ],\n",
       "         [ 0.20000005,  0.4666667 ,  0.27843142],\n",
       "         [-0.02745098,  0.22352946, -0.3490196 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  0.9843137 ,  0.99215686],\n",
       "         ...,\n",
       "         [-0.47450978, -0.40392154, -0.44313723],\n",
       "         [-0.4980392 , -0.41176468, -0.44313723],\n",
       "         [-0.54509807, -0.46666664, -0.47450978]],\n",
       "\n",
       "        [[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 0.99215686,  0.99215686,  0.99215686],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [-0.4588235 , -0.372549  , -0.41960782],\n",
       "         [-0.4823529 , -0.38039213, -0.4352941 ],\n",
       "         [-0.5294118 , -0.4352941 , -0.46666664]],\n",
       "\n",
       "        [[ 0.9607843 ,  0.9764706 ,  0.96862745],\n",
       "         [ 0.9843137 ,  1.        ,  0.99215686],\n",
       "         [ 0.99215686,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [-0.41176468, -0.3098039 , -0.38039213],\n",
       "         [-0.44313723, -0.31764704, -0.3960784 ],\n",
       "         [-0.4823529 , -0.36470586, -0.41960782]]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09dbe0fb-ffd1-4075-832d-e558d0b39a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cbef359f-ab17-4412-aa50-7ce4fce0cf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "541b1e3f-77e1-4d81-bf32-a9cc2cf621bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e5a39df-76cd-4af3-8a14-752786179b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = preds[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73fb9e6d-4847-467f-a3a6-feb5b713ff86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9637459"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0][top]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b922c68d-cf3c-4996-b1be-5653b3d6124d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n07742313', 'Granny_Smith', 0.9637459),\n",
       "  ('n07753113', 'fig', 0.014616218),\n",
       "  ('n07720875', 'bell_pepper', 0.009934579),\n",
       "  ('n12620546', 'hip', 0.004221914),\n",
       "  ('n12768682', 'buckeye', 0.0020895384)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_predictions(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f01e2be5-e1e1-4dd4-a252-48b83e577260",
   "metadata": {},
   "outputs": [],
   "source": [
    "me = image.load_img('img_2.jpg', target_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f36b2931-031e-4a54-8204-e276afca577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "me = image.img_to_array(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "036f3ce7-f1b1-4081-bd43-f8209159ba65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46f59a64-2111-4ed5-a78c-35086986b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "me = np.expand_dims(me, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dbdcf7f-521a-4e32-a929-6c68aba89064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a55d6e0d-7d78-45de-98a0-2382a38f0a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "me = preprocess_input(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d140fbc-4dbe-4d60-8692-18b79f1df628",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_me = model.predict(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "219e1a39-3729-4779-8fec-9bf99a9040e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('n02113712', 'miniature_poodle', 0.6490703),\n",
       "  ('n02113624', 'toy_poodle', 0.31763998),\n",
       "  ('n02113799', 'standard_poodle', 0.03126336),\n",
       "  ('n04162706', 'seat_belt', 0.00070904725),\n",
       "  ('n04399382', 'teddy', 0.0003698388)]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_predictions(pred_me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72263d85-e762-4f91-8b6d-dda2a8f9be61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
